{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codeskavy/Virtual_Tryon/blob/main/agnostic%26parse_agnostic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "NzWkrT-2_-P9",
        "outputId": "e030e0e6-612d-4965-a578-3a459980b84a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/data/image'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a5a70a5b5be8>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mim_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Load image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/data/image'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_img_agnostic(img, parse, pose_data, w=768, h=1024):\n",
        "    parse_array = np.array(parse)\n",
        "    parse_head = ((parse_array == 4).astype(np.float32) +\n",
        "                  (parse_array == 13).astype(np.float32))\n",
        "    parse_lower = ((parse_array == 9).astype(np.float32) +\n",
        "                   (parse_array == 12).astype(np.float32) +\n",
        "                   (parse_array == 16).astype(np.float32) +\n",
        "                   (parse_array == 17).astype(np.float32) +\n",
        "                   (parse_array == 18).astype(np.float32) +\n",
        "                   (parse_array == 19).astype(np.float32))\n",
        "\n",
        "    r = 20\n",
        "    agnostic = img.copy()\n",
        "    agnostic_draw = ImageDraw.Draw(agnostic)\n",
        "\n",
        "    length_a = np.linalg.norm(pose_data[5] - pose_data[2])\n",
        "    length_b = np.linalg.norm(pose_data[12] - pose_data[9])\n",
        "    point = (pose_data[9] + pose_data[12]) / 2\n",
        "    pose_data[9] = point + (pose_data[9] - point) / length_b * length_a\n",
        "    pose_data[12] = point + (pose_data[12] - point) / length_b * length_a\n",
        "\n",
        "    # mask arms\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 5]], 'gray', width=r*10)\n",
        "    for i in [2, 5]:\n",
        "        pointx, pointy = pose_data[i]\n",
        "        agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n",
        "    for i in [3, 4, 6, 7]:\n",
        "        if (pose_data[i - 1, 0] == 0.0 and pose_data[i - 1, 1] == 0.0) or (pose_data[i, 0] == 0.0 and pose_data[i, 1] == 0.0):\n",
        "            continue\n",
        "        agnostic_draw.line([tuple(pose_data[j]) for j in [i - 1, i]], 'gray', width=r*10)\n",
        "        pointx, pointy = pose_data[i]\n",
        "        agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n",
        "\n",
        "    # mask torso\n",
        "    for i in [9, 12]:\n",
        "        pointx, pointy = pose_data[i]\n",
        "        agnostic_draw.ellipse((pointx-r*3, pointy-r*6, pointx+r*3, pointy+r*6), 'gray', 'gray')\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 9]], 'gray', width=r*6)\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [5, 12]], 'gray', width=r*6)\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [9, 12]], 'gray', width=r*12)\n",
        "    agnostic_draw.polygon([tuple(pose_data[i]) for i in [2, 5, 12, 9]], 'gray', 'gray')\n",
        "\n",
        "    # mask neck\n",
        "    pointx, pointy = pose_data[1]\n",
        "    agnostic_draw.rectangle((pointx-r*7, pointy-r*7, pointx+r*7, pointy+r*7), 'gray', 'gray')\n",
        "    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_head * 255), 'L'))\n",
        "    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_lower * 255), 'L'))\n",
        "\n",
        "    return agnostic\n",
        "\n",
        "\n",
        "# Modify paths for Google Colab environment\n",
        "data_path = '/content/drive/MyDrive/data'  # Adjust this path\n",
        "output_path = '/content/output/output_agnostic'  # Adjust this path\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "for im_name in tqdm(sorted(os.listdir(os.path.join(data_path, 'image')))):\n",
        "    # Load image\n",
        "    img_name = im_name\n",
        "    img = Image.open(os.path.join(data_path, 'image', img_name))\n",
        "\n",
        "    # Load pose image\n",
        "    pose_name = im_name.replace('.jpg', '_keypoints.json')\n",
        "\n",
        "    try:\n",
        "        with open(os.path.join(data_path, 'openpose_json', pose_name), 'r') as f:\n",
        "            pose_label = json.load(f)\n",
        "            pose_data = pose_label['people'][0]['pose_keypoints_2d']\n",
        "            pose_data = np.array(pose_data)\n",
        "            pose_data = pose_data.reshape((-1, 3))[:, :2]\n",
        "    except (IndexError, FileNotFoundError, KeyError) as e:\n",
        "        print(f\"Error processing {pose_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Load parsing image\n",
        "    parse_name = im_name.replace('.jpg', '.png')\n",
        "    parse = Image.open(os.path.join(data_path, 'image-parse-v3', parse_name))\n",
        "\n",
        "    agnostic = get_img_agnostic(img, parse, pose_data)\n",
        "\n",
        "    # Save the agnostic image\n",
        "    output_file = os.path.join(output_path, img_name)\n",
        "    agnostic.save(output_file)\n",
        "    print(f\"Saved {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import argparse\n",
        "from tqdm.notebook import tqdm  # Use tqdm.notebook for Colab's notebook interface\n",
        "\n",
        "# Mount Google Drive if necessary\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "data_path = '/content/drive/My Drive/data'  # Adjust with your Google Drive path\n",
        "output_path = '/content/drive/My Drive/output/output_agnostic'  # Adjust with your Google Drive path\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "oVm5bQ93Eus2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_agnostic(img, parse, pose_data, w=768, h=1024):\n",
        "    parse_array = np.array(parse)\n",
        "    parse_head = ((parse_array == 4).astype(np.float32) +\n",
        "                  (parse_array == 13).astype(np.float32))\n",
        "    parse_lower = ((parse_array == 9).astype(np.float32) +\n",
        "                   (parse_array == 12).astype(np.float32) +\n",
        "                   (parse_array == 16).astype(np.float32) +\n",
        "                   (parse_array == 17).astype(np.float32) +\n",
        "                   (parse_array == 18).astype(np.float32) +\n",
        "                   (parse_array == 19).astype(np.float32))\n",
        "\n",
        "    r = 20\n",
        "    agnostic = img.copy()\n",
        "    agnostic_draw = ImageDraw.Draw(agnostic)\n",
        "\n",
        "    length_a = np.linalg.norm(pose_data[5] - pose_data[2])\n",
        "    length_b = np.linalg.norm(pose_data[12] - pose_data[9])\n",
        "    point = (pose_data[9] + pose_data[12]) / 2\n",
        "    pose_data[9] = point + (pose_data[9] - point) / length_b * length_a\n",
        "    pose_data[12] = point + (pose_data[12] - point) / length_b * length_a\n",
        "\n",
        "    # mask arms\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 5]], 'gray', width=r*10)\n",
        "    for i in [2, 5]:\n",
        "        pointx, pointy = pose_data[i]\n",
        "        agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n",
        "    for i in [3, 4, 6, 7]:\n",
        "        if (pose_data[i - 1, 0] == 0.0 and pose_data[i - 1, 1] == 0.0) or (pose_data[i, 0] == 0.0 and pose_data[i, 1] == 0.0):\n",
        "            continue\n",
        "        agnostic_draw.line([tuple(pose_data[j]) for j in [i - 1, i]], 'gray', width=r*10)\n",
        "        pointx, pointy = pose_data[i]\n",
        "        agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n",
        "\n",
        "    # mask torso\n",
        "    for i in [9, 12]:\n",
        "        pointx, pointy = pose_data[i]\n",
        "        agnostic_draw.ellipse((pointx-r*3, pointy-r*6, pointx+r*3, pointy+r*6), 'gray', 'gray')\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 9]], 'gray', width=r*6)\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [5, 12]], 'gray', width=r*6)\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [9, 12]], 'gray', width=r*12)\n",
        "    agnostic_draw.polygon([tuple(pose_data[i]) for i in [2, 5, 12, 9]], 'gray', 'gray')\n",
        "\n",
        "    # mask neck\n",
        "    pointx, pointy = pose_data[1]\n",
        "    agnostic_draw.rectangle((pointx-r*7, pointy-r*7, pointx+r*7, pointy+r*7), 'gray', 'gray')\n",
        "    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_head * 255), 'L'))\n",
        "    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_lower * 255), 'L'))\n",
        "\n",
        "    return agnostic\n"
      ],
      "metadata": {
        "id": "sDnC1OiNE1ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through images in the data directory\n",
        "for im_name in tqdm(os.listdir(os.path.join(data_path, 'image'))):\n",
        "    # Load image\n",
        "    img_name = im_name\n",
        "    img = Image.open(os.path.join(data_path, 'image', img_name))\n",
        "\n",
        "    # Load pose image\n",
        "    pose_name = im_name.replace('.jpg', '_keypoints.json')\n",
        "    try:\n",
        "        with open(os.path.join(data_path, 'openpose_json', pose_name), 'r') as f:\n",
        "            pose_label = json.load(f)\n",
        "            pose_data = pose_label['people'][0]['pose_keypoints_2d']\n",
        "            pose_data = np.array(pose_data)\n",
        "            pose_data = pose_data.reshape((-1, 3))[:, :2]\n",
        "    except (IndexError, FileNotFoundError, KeyError) as e:\n",
        "        print(f\"Error processing {pose_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Load parsing image\n",
        "    parse_name = im_name.replace('.jpg', '.png')\n",
        "    parse = Image.open(os.path.join(data_path, 'image-parse-v3', parse_name))\n",
        "\n",
        "    # Generate agnostic image\n",
        "    agnostic = get_img_agnostic(img, parse, pose_data)\n",
        "\n",
        "    # Save the agnostic image\n",
        "    agnostic_file = os.path.join(output_path, img_name)\n",
        "    agnostic.save(agnostic_file)\n",
        "    print(f\"Saved agnostic image: {agnostic_file}\")\n",
        "\n",
        "    # Optionally, save the parse image as well\n",
        "    parse_file = os.path.join(output_path, parse_name)\n",
        "    parse.save(parse_file)\n",
        "    print(f\"Saved parse image: {parse_file}\")\n"
      ],
      "metadata": {
        "id": "zc61ZNgvE5d9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}